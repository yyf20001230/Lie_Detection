{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wave\n",
    "import time\n",
    "import pickle\n",
    "import pyaudio\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io.wavfile import read\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizer_v1 import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio):\n",
    "\n",
    "    signal, sr = librosa.load(audio, res_type = 'kaiser_fast')\n",
    "    mfccs = librosa.feature.mfcc(signal, n_mfcc=13, sr = sr)\n",
    "    delta_mfccs = librosa.feature.delta(mfccs)\n",
    "    delta2_mfccs = librosa.feature.delta(mfccs, order=2)\n",
    "    comprehensive_mfccs = np.concatenate((mfccs, delta_mfccs, delta2_mfccs))\n",
    "    comprehensive_mfccs = np.mean(comprehensive_mfccs.transpose(), axis = 0)\n",
    "    comprehensive_mfccs.reshape((-1,1))\n",
    "    return comprehensive_mfccs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio_train():\n",
    "    Name = (input(\"Please Enter Your Name:\"))\n",
    "    for count in range(5):\n",
    "        FORMAT = pyaudio.paInt16\n",
    "        CHANNELS = 1\n",
    "        RATE = 44100\n",
    "        CHUNK = 512\n",
    "        RECORD_SECONDS = 10\n",
    "        device_index = 2\n",
    "        audio = pyaudio.PyAudio()\n",
    "        print(\"----------------------record device list---------------------\")\n",
    "        info = audio.get_host_api_info_by_index(0)\n",
    "        numdevices = info.get('deviceCount')\n",
    "        for i in range(numdevices):\n",
    "            if audio.get_device_info_by_host_api_device_index(0, i).get('maxInputChannels') > 0:\n",
    "                print(\"Input Device id \" + str(i) + \" - \" +\n",
    "                      audio.get_device_info_by_host_api_device_index(0, i).get('name'))\n",
    "        print(\"-------------------------------------------------------------\")\n",
    "        index = int(input())\n",
    "        print(\"recording via index \"+str(index))\n",
    "        stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                            rate=RATE, input=True, input_device_index=index,\n",
    "                            frames_per_buffer=CHUNK)\n",
    "        print(\"recording started\")\n",
    "        Recordframes = []\n",
    "        for i in range(int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "            data = stream.read(CHUNK)\n",
    "            Recordframes.append(data)\n",
    "        print(\"recording stopped\")\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        audio.terminate()\n",
    "        OUTPUT_FILENAME = Name+\"-sample\"+str(count)+\".wav\"\n",
    "        WAVE_OUTPUT_FILENAME = os.path.join(\"training_set\", OUTPUT_FILENAME)\n",
    "        trainedfilelist = open(\"training_set_addition.txt\", 'a')\n",
    "        trainedfilelist.write(OUTPUT_FILENAME+\"\\n\")\n",
    "        waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "        waveFile.setnchannels(CHANNELS)\n",
    "        waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "        waveFile.setframerate(RATE)\n",
    "        waveFile.writeframes(b''.join(Recordframes))\n",
    "        waveFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio_test():\n",
    "\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 1\n",
    "    RATE = 44100\n",
    "    CHUNK = 512\n",
    "    RECORD_SECONDS = 10\n",
    "    device_index = 2\n",
    "    audio = pyaudio.PyAudio()\n",
    "    print(\"----------------------record device list---------------------\")\n",
    "    info = audio.get_host_api_info_by_index(0)\n",
    "    numdevices = info.get('deviceCount')\n",
    "    for i in range(0, numdevices):\n",
    "        if (audio.get_device_info_by_host_api_device_index(0, i).get('maxInputChannels')) > 0:\n",
    "            print(\"Input Device id \", i, \" - \",\n",
    "                  audio.get_device_info_by_host_api_device_index(0, i).get('name'))\n",
    "    print(\"-------------------------------------------------------------\")\n",
    "    index = int(input())\n",
    "    print(\"recording via index \"+str(index))\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                        rate=RATE, input=True, input_device_index=index,\n",
    "                        frames_per_buffer=CHUNK)\n",
    "    print(\"recording started\")\n",
    "    Recordframes = []\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        Recordframes.append(data)\n",
    "    print(\"recording stopped\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    savedname = input(\"Please input saved wave filename: \")\n",
    "    OUTPUT_FILENAME = savedname + \".wav\"\n",
    "    WAVE_OUTPUT_FILENAME = \"testing_set/\" + OUTPUT_FILENAME\n",
    "    trainedfilelist = open(\"testing_set_addition.txt\", 'w')\n",
    "    for fname in os.listdir(\"testing_set/\"):\n",
    "        if fname.endswith('.wav'):\n",
    "            trainedfilelist.write(fname + \"\\n\")\n",
    "    trainedfilelist.write(OUTPUT_FILENAME +\"\\n\")\n",
    "    waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    waveFile.setnchannels(CHANNELS)\n",
    "    waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "    waveFile.setframerate(RATE)\n",
    "    waveFile.writeframes(b''.join(Recordframes))\n",
    "    waveFile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_model():\n",
    "\n",
    "    source = \"training_set/\"\n",
    "    train_file = \"training_set_addition.txt\"\n",
    "    \n",
    "    file_paths = open(train_file, 'r')\n",
    "    features = []\n",
    "\n",
    "    for path in file_paths:\n",
    "        path = path.strip()\n",
    "        class_label = path.split(\"-\")[0]\n",
    "        print(path)\n",
    "        data = extract_features(source + path)\n",
    "        features.append([data, class_label])\n",
    "\n",
    "    featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "    # Convert features and corresponding classification labels into numpy arrays\n",
    "    X = np.array(featuresdf.feature.tolist())\n",
    "    y = np.array(featuresdf.class_label.tolist())\n",
    "\n",
    "    # Encode the classification labels\n",
    "    le = LabelEncoder()\n",
    "    yy = to_categorical(le.fit_transform(y))\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 127)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(yy.shape[1]))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "    # Evaluate the model and pretrain with test data\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(\"pretraining accuracy: \" + str(score[1] * 100))\n",
    "\n",
    "     # train with train data\n",
    "    model.fit(X, yy, batch_size=32, epochs=5, verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "    # evaluate the accuracy on both data\n",
    "    score = model.evaluate(x_train, y_train, verbose=0)\n",
    "    print(\"Training Accuracy: {0:.2%}\".format(score[1]))\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(\"Testing Accuracy: {0:.2%}\".format(score[1]))\n",
    "\n",
    "    source = \"testing_set/\"\n",
    "    test_file = \"testing_set_addition.txt\"\n",
    "    file_paths = open(test_file, 'r')\n",
    "\n",
    "    # Read the test directory and get the list of test audio files\n",
    "    for path in file_paths:\n",
    "\n",
    "        path = path.strip()\n",
    "        print(path)\n",
    "        data = extract_features(source + path)\n",
    "        label = model.predict(X[:,0])\n",
    "        print(label)\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model():\n",
    "\n",
    "    source = \"testing_set/\"\n",
    "    modelpath = \"trained_models/\"\n",
    "    test_file = \"testing_set_addition.txt\"\n",
    "    file_paths = open(test_file, 'r')\n",
    "\n",
    "    gmm_files = [os.path.join(modelpath, fname) for fname in\n",
    "                 os.listdir(modelpath) if fname.endswith('.gmm')]\n",
    "\n",
    "    # Load the Gaussian gender Models\n",
    "    models = [pickle.load(open(fname, 'rb')) for fname in gmm_files]\n",
    "    speakers = [fname.split(\"\\\\\")[-1].split(\".gmm\")[0] for fname\n",
    "                in gmm_files]\n",
    "\n",
    "    # Read the test directory and get the list of test audio files\n",
    "    for path in file_paths:\n",
    "\n",
    "        try:\n",
    "            path = path.strip()\n",
    "            sr, audio = read(source + path)\n",
    "            vector = extract_features(audio)\n",
    "        except:\n",
    "            print(\"error: \" + path + \" not found\")\n",
    "            continue\n",
    "\n",
    "        log_likelihood = np.zeros(len(models))\n",
    "\n",
    "        for i in range(len(models)):\n",
    "            gmm = models[i]  # checking with each model one by one\n",
    "            scores = np.array(gmm.score(vector))\n",
    "            log_likelihood[i] = scores.sum()\n",
    "\n",
    "        winner = np.argmax(log_likelihood)\n",
    "        print(path,\" detected as - \", speakers[winner])\n",
    "        time.sleep(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kailyn-sample4.wav\n",
      "Kailyn-sample1.wav\n",
      "Kailyn-sample0.wav\n",
      "Kailyn-sample2.wav\n",
      "Kailyn-sample3.wav\n",
      "Frank-sample4.wav\n",
      "Frank-sample2.wav\n",
      "Frank-sample3.wav\n",
      "Frank-sample1.wav\n",
      "Frank-sample0.wav\n",
      "Godfather-sample0.wav\n",
      "Godfather-sample1.wav\n",
      "Godfather-sample2.wav\n",
      "Godfather-sample3.wav\n",
      "Godfather-sample4.wav\n",
      "pretraining accuracy: 33.33333432674408\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 20.5193 - accuracy: 0.4667 - val_loss: 12.0738 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 25.4268 - accuracy: 0.4000 - val_loss: 7.9591 - val_accuracy: 0.3333\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 40.7056 - accuracy: 0.1333 - val_loss: 10.2194 - val_accuracy: 0.3333\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 30.2805 - accuracy: 0.2667 - val_loss: 16.6305 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 38.2686 - accuracy: 0.3333 - val_loss: 13.3580 - val_accuracy: 0.6667\n",
      "Training Accuracy: 66.67%\n",
      "Testing Accuracy: 66.67%\n",
      "godfather.wav\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 39) for input KerasTensor(type_spec=TensorSpec(shape=(None, 39), dtype=tf.float32, name='dense_59_input'), name='dense_59_input', description=\"created by layer 'dense_59_input'\"), but it was called on an input with incompatible shape (None,).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/frank/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/frank/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/frank/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/frank/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/Users/frank/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/frank/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 228, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_20\" (type Sequential).\n    \n    Input 0 of layer \"dense_59\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None,), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-c50d22f9a283>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mrecord_audio_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32melif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchoice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtrain_and_test_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32melif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchoice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mrecord_audio_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-146-7626466b41b8>\u001b[0m in \u001b[0;36mtrain_and_test_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/frank/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/frank/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/frank/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/frank/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/Users/frank/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/frank/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 228, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_20\" (type Sequential).\n    \n    Input 0 of layer \"dense_59\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None,), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    choice = int(input(\n",
    "        \"\\n 1.Record audio for training \\n 2.Train Model \\n 3.Record audio for testing \\n 4.Test Model\\n\"))\n",
    "    if(choice == 1):\n",
    "        record_audio_train()\n",
    "    elif(choice == 2):\n",
    "        train_and_test_model()\n",
    "    elif(choice == 3):\n",
    "        record_audio_test()\n",
    "    elif(choice == 4):\n",
    "        test_model()\n",
    "    if(choice > 4):\n",
    "        exit()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "24b17b925cb255c3f5f9d44279af6acbce2f518dd20c49d83bc1f6775a53d6cb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
